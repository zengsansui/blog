---
title: "音视频基础"
date: 2019-06-23T12:13:30+08:00
Tags:
- Video 
Categories:
- Video
toc: true
img: ""
---

## 视频播放原理

- 音视频技术
  - 封装技术
  - 视频压缩编码技术
  - 音频压缩编码技术
  - 流媒体协议技术

视频播放器播放一个视频文件，需要经过以下几个步骤：解协议，解封装，解码音视频，音视频同步。如果播放本地文件则不需要解协议。

![音视频播放过程](https://img-blog.csdn.net/20140201120523046?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGVpeGlhb2h1YTEwMjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

- **解协议**：将流媒体协议的数据，解析为标准的相应的封装格式数据。解协议的过程中会除掉信令数据（这些信令数据包含对播放的控制，或者对网络状态的描写）而只保留音视频数据。如RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。
- **解封装**：将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据。封装格式种类很多，比如MP4,MKV,RMVB,TS,AVI等，它的作用就是将已经压缩编码的视频数据和音频数据按照一定的格式放到一起。比如，FLV格式的数据，经过解封装后，输出H.264编码的视频码流和AAC编码的音频码流。
- **解码**：将音视频压缩编码数据，解码成为非压缩的音视原始数据。音频的压缩编码标准包含AAC,MP3,AC-3等，视频的压缩编码标准包括H.264,MPEG2,VC-1等。通过解码，压缩编码的视频数据输出成为非压缩的颜色数据，例如YUV4420,RGB等；压缩编码的音频数据输出成为非压缩的音频抽样数据。例如：PCM数据。
- **音视频同步**：根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据发送至系统的显卡和声卡播放出来。

## YUV、RGB像素数据处理

- **分离YUV420P像素数据中的YUV分量**：

```sh
如果视频帧的宽和高分别为W和H，
那么一帧YUV420像素数据一共占用W*H*3/2 Byte的数据。
其中前W*H存储Y，
接着W*H*1/4存储U，
最后W*H*1/4存储V。
```

- **将YUV444P像素数据中的YUV分量**：

```sh
如果视频帧的宽和高分别为W和H，
那么一帧YUV444P像素数据一共占用W*H*3 Byte的数据。
其中前W*H Byte存储Y，
接着W*H Byte存储U，
最后W*H Byte存储V。
```

- **将YUV420P像素数据去掉颜色(变成灰度图)**：

```sh
如果想把YUV格式像素数据变成灰度图像，
只需要将U、V设置成128即可。
这是因为U、V是图像中的经过偏置处理的色度分量。
色度分量在偏置处理的取值范围是-128至127，
这时候的无色对应的是0值。
经过偏置后色度分量取值范围变成了0至255，
因此无色对应的就是128了。
```

- **将YUV420P像素数据亮度减半**：

```sh
将图像的亮度减半，只要将图像的每个像素的Y值取出来分别进行除以2就可以了。
```

- **将YUV420P像素数据的周围加上边框**

```sh
可以通过修改YUV数据中特定位置的亮度分量Y的数值，给图像添加一个“边框”的效果
```

- **计算两个YUV420P像素数据的PSNR**

```sh
PSNR是最基本的视频质量评价方法，通常情况下PSNR都在20-50的范围内，取值越高，受损图质量越好。
```

- **分离RGB24像素数据中的RGB分量**：

```sh
RGB24格式的每个像素的三个分量是连续存储的。
一帧的宽高分别为W,H的RGB24图像一共占用W*H*3 Byte的存储空间。
RGB24格式规定首先存储第一个像素的RGB,然后存储第二像素的R,G,B...以此类推。
类似于YUV420P的存储方式称为Planar方式，而类似于RGB24的存储方式称为Packed方式。
```

- **将RGB格式像素数据转换为YUV420P格式像素数据**：

```sh
RGB到YUV的转换公式：
Y= 0.299*R+0.587*G+0.114*B
U=-0.147*R-0.289*G+0.463*B
V= 0.615*R-0.515*G-0.100*B
在转换过程中有一下几点需要注意：
1.RGB24存储方式是Packed方式，YUV420P存储方式是Planar方式
2.U，V在水平和垂直方向的取样数是Y的一半
```

## PCM音频采样数据处理

- **分离PCM16LE双声道音频采样数据的左声道和右声道

```sh
PCM16LE双声道数据中左声道和右声道的采样值是间隔存储的。
每个采样值占用2 Byte空间。
注：本文中声音样值的采样频率一律是44100Hz，
采样格式一律为16LE。“16”代表采样位数是16bit。
由于1Byte=8bit，所以一个声道的一个采样值占用2Byte。
“LE”代表Little Endian，代表2 Byte采样值的存储方式为高位存在高地址中。
```

- **将PCM16LE双声道音频采样数据中左声道的音量降一半**

```sh
在读出左声道2 Byte的取样值后，将其当作C语言的一个short类型的变量。
将该数值除以2即可。
```

- **将PCM16LE双声道音频采样数据的声音速度提高一倍**：

```sh
只采样了每个声道奇数点的样值
```

- **将PCM16LE双声道采样数据转换为PCM8音频采样数据**：

```sh
PCM16LE格式的采样数据的取值范围是-32768到32768，
而PCM8格式的采样的数据的取值范围是0到255。
所以PCM16LE转换到PCM8需要经过两个步骤：
1.将-32768到32768的16bit有符号数值转换为-128到127的8bit有符号数值
2.将-128到127的8bit有符号数值转换为0到255的8bit无符号数值。
16bit采样数据是通过short类型变量存储的，
而8bit采样数据四通过unsigned char类型存储的。
8bit PCM的音质不如16bit PCM的音质
```

- **将PCM16LE双声道音频采样数据转换为WAVE格式音频数据**：

```sh
WAVE格式音频(扩展名为.wav)是Windows系统中常见的一种音频。
该格式的实质就是在PCM文件的前面加了一个文件头。
```

## H264视频码流解析

YUV/RGB处理程序以及PCM处理程序都属于音视频原始数据的处理程序。H264处理的是视频码流。

- 原理
H.264原始码流(又称为裸流)是一个由一个一个NALU组成的。结构如下：
![音视频播放过程](https://img-blog.csdn.net/20160118001549018)

其中每个NALU之间通过startcode（起始码）进行分割。起始码分为两种：0x000001(3byte)或者0x00000001(4byte)。如果NALU对应的slice为一帧的就开始用0x00000001，否则就用0x000001。H.264码流解析的步骤就是首先从码流的搜索0x000001和0x00000001，分离出NALU；然后分析NALU的各个字段。

## AAC音频码流解析

- 原理
AAC原始码流(称为裸流)是由一个一个的ADTS frame组成的。结构图如下：
![音视频播放过程](https://img-blog.csdn.net/20160118101611729)

每个ADTS frame之间通过syncword（同步字）进行分割。同步字为0xFFF（二进制111111111111）.AAC码流解析的步骤首先从码流中搜索0x0FFF,分离出ADTS fram的首部各个字段。

## FLV封装格式解析

- 原理
FLV封装格式是由一个FLV Header文件头和一个一个的Tag组成的。Tag中包含了音频数据以及视频数据。FLV结构图如下：
![音视频播放过程](https://img-blog.csdn.net/20160118103525777)

## UDP-RTP协议解析

- 原理

## ffmpeg程序的使用（ffmpeg.exe，ffplay.exe，ffprobe.exe）

- ffmpeg.exe：是用于转码的应用程序；

```sh
# 将input.avi转码成output.ts，并设置视频的码率为640kbps
ffmpeg -i input.avi -b:v 640k output.ts  
```

- ffplay.exe:是用于播放的应用程序。

```sh
# 播放test.avi
ffplay test.avi  
```

- ffprobe.exe:是用于查看文件格式的应用程序。

SDL是显示用的工具

封装格式：MP4,RMVB,TS,EFV,AVI
视频编码数据：H.264,MPEG2,VC-1,HEVC
音频编码数据：AAC,MP3,AC-3
视频像素数据：YUV420P,RGB
音频采样数据：PCM

信息查看工具：
综合信息查看：MediaInfo
二进制信息查看：UItraEdit
单项详细分析：
封装格式：Elecard Format Analyzer
视频编码数据：Elecard Stream Eye(H.264)
视频像素数据：YUV Player
音频采样数据：Adobe Audition

- MPEF2-TS格式简介：不包含头文件，数据大小固定(188byte)的TS Packet构成。可从中间播放。
- FLV格式：包含头文件。数据大小不固定的Tag构成。若头不对，整个视频就废了。

- 视频编码的作用：将视频像素数据(RGB,YUV)压缩成为视频码流，从而降低视频的数据量。
- 视频编码格式:HEVC(H.265),H.264,MPEG4,MPEG2.

- H.264格式简介：数据大小由不固定的NALU构成，最常见情况下一个NALU存储了1帧画面的压缩编码后的数据。
- I帧
- P帧：依赖前面的帧
- B帧：双向依赖，依赖前后的帧

- 音频编码的作用：将音频采样数据（PCM等）压缩成为音频码流，从而降低音频的数据量
- AAC,AC-3（电影）,MP3（AAC取代MP3）,WMA（微软）

- AAC格式：由数据大小不固定的ADTS构成

### 视频像素数据

- 视频像素数据作用：保存了屏幕上每个像素点的像素值。
- 格式：RGB24,RGB32,YUV420P,YUV422P,YUV444P,最常见YUV420P。
- 特定：视频像素数据体积很大，一把情况下1小时高清视频的RGB24格式的数据体积为：`3600*25*1920*1080*3=559.9GBbyte`
- 查看工具：YUV Player
- RGB格式：RGB24依次存储了每个像素点的RGB信息（BMP文件中存储的就是RGB格式的像素数据）
- YUV格式：人眼对亮度敏感而对色度不敏感，因而将亮度信息和速度信息分离。YUV格式中，Y只包含亮度信息，而UV只包含色度信息。
- YUV存储方式：YUV420P首先存储了整张图像的Y信息，然后存储整张图像的U信息，最后存储整张图像的V信息。

### 音频采样数据

- 作用：保存了音频中每个采样点的值/
- 特点：音频采样数据体积很大，一般情况下一首4分钟的PCM格式的歌曲体积为：`4*60*44100*2*2=42.3Mbyte`
- 工具：Adobe Audition
- 业内采样率为：44100Hz,采样精度16bit
- PCM格式：单声道的情况下按照顺序存储每个采样点的数据；双声道的情况下按照“左右，左右”的顺序存储每个采样点两个声道的数据

## FFmpeg命令行工具

- **ffmpeg.exe的使用**：
- 功能：用于视频的转码
- 最简单的命令

```sh
ffmpeg -i input.avi -b:v 640k output.ts
# 该命令将当前文件夹下的input.avi文件转换为output.ts，并将output.ts文件视频的码率设置为640kbps.
```

- 命令格式：

```sh
ffmpeg -i [输入文件陆军] -b:v [输出视频码率] [输出文件路径]
# 所有你的参数都是以键值对的形式指定的，例如输入文件参数是-i，而参数值是文件路径；输出视频码率参数是“-b:v"，而参数值是视频的码率值。但是注意位于最后面的输出文件路径前面不包含参数名称。
```

- 命令参数：

```sh
-h            帮助
-i filename   输入文件
-t duration   设置处理时间，格式为hh:mm:ss
-ss position  设置起始时间，格式为hh:mm:ss
-b:v bitrate  设置视频码率
-b:a bitrate  设置音频码率
-r fps      设置帧率
-s wxh      设置帧大小，格式为WxH
-c:v codec  设置视频编码器
-c:a codec  设置音频编码器
-ar freq 设置音频采样率
```

- **ffpaly.exe的使用
- 功能：用于播放视频
- 最简单的命令：

```sh
ffplay input.mp4
```

## 视频解码知识

- 纯净的视频解码流程
  - 压缩编码视频->像素数据
  - 例如解码H.264,就是H.264码流->YUV。
- 一般的视频解码流：
  - 视频码流一般存储在一定的封装格式中。封装格式中通常还包含音频码流等内容。
  - 对于封装格式中的视频，需要先从封装格式中提取视频码流，然后再进行解码。
  - 例如解码MKV格式的视频文件，就是MKV->H.264->YUV

## FFmpeg库简介：

- avcodec:编解码(最重要的库)
- avformat:封装格式处理
- avfilter:滤镜特效处理
- avdevice:各种设备的输入输出
- avutil:工具库(大部分库都需要这个库的支持)
- postproc：后加工
- swresample:音频采样数据格式转换
- swscale:视频像素数据格式转换

## FFmpeg解码流程

## FFmpeg数据结构分析

- AVFormatContext
  - iformat:输入视频的AVInputFormat
  - nb_streams:输入视频的AVStream个数
  - streams：输入视频的AVStream[]数组
  - duration：输入视频的时长(以微妙为单位)
  - bit_rate:输入视频的码率
- AVInputFormat
  - name:封装格式名称
  - long_name:封装格式的长名称
  - extensions:封装格式的扩展名
  - id：封装格式的ID
  - 一些封装格式处理的接口函数
- AVStream
  - id：序号
  - codec：流对应的AVCodecContext
  - time_base:该流的时基
  - r_frame_rate:该流的帧率
- AVCodecContext
  - codec：编解码器的AVCodec
  - width，height：图像的宽高（只针对视频）
  - pix_fmt:像素格式（视频）
  - sample_rate:采样率(只针对音频)
  - channels：声道数（音频）
  - sample_fmt:采样格式（音频）
- AVCodec
  - name:编解码器名称
  - long_name:编解码器长名称
  - type:编解码器类型
  - id:编解码器ID
  - 一些编解码器的接口函数
- AVPacket（装H264）
  - pts:显示时间戳
  - dts:解码时间戳
  - data:压缩编码数据
  - size:压缩编码数据大小
  - stream_index:所属的AVStream
- AVFrame（装YUV）
  - data:解码后的图像像素数据(音频采样数据)
  - linesize:对视频来说图像中一行像素的大小。对音频来说整个音频帧的大小
  - width，height：图像的宽高（视频）
  - key_frame:是否为关键帧（视频）
  - pict_type:帧类型（视频），比如：I,P,B









- 编码（encode）：通过特定的压缩技术，将某个视频的视频流格式转换成另一种视频格式的视频流方式（减少字节数）。
- 解码（decode）：通过特定的解压技术，将某个视频格式的视频流转换为另一种视频格式的视频流方式（还原操作，将编码数据还原成编码前的数据）。
- 转码（transcode）：视频转码技术将视频信号从一种格式转换成另一种格式。

- 视频编码：

```sh
YUV420/422 -> H264；
RGB888 -> H264;
YUV420 ->h263;

420占的字节数比较少
```

- 音频编码：

```sh
PCM（原始）-> AAC
PCM(原始) -> G726
PCM(原始) -> G711
```

- 视频转码：改变分辨率(resolution，实际就是宽高),改变帧率(frame rate,人眼15帧以上看着基本流畅的)，改变比特率(bit rate,影响带宽，大小)等编码参数。比如关键帧，I帧
- 音频转码：改变采样率(sample rate),改变通道数(channels),改变位宽（sample format）
- 封装(mux):复用，按一定格式组织原始音视频流；
- 解封装(demux):解复用，按一定格式解析出原始音视频流；

- ES流：原始流，直接从编码器出来的数据流；
- PES流：ES形成的分组称为PES流，用来传递ES的一种数据布局。
- TS流：ES形成的分组称为TS流，用来传递ES的一种数据布局。(网上传输)

- rtsp流：实时流传输协议，是TCP/IP协议体系中的一个应用层协议，控制协议（摄像机）；
- rtmp流：实时消息传输协议(直播平台)；
- hls流：主要用于PC和apple终端的音视频服务。包括一个么m3u8索引文件，TS媒体分片文件(苹果机)。

- 流媒体：采用流式方式传输方式在Internet播放的媒体格式。
